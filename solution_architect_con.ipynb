{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #466\n",
    "A company wants to migrate virtual Microsoft workloads from an on-premises data center to AWS. The company has successfully tested a few sample workloads on AWS. The company also has created an AWS Site-to-Site VPN connection to a VPC. A solutions architect needs to generate a total cost of ownership (TCO) report for the migration of all the workloads from the data center.\n",
    "\n",
    "Simple Network Management Protocol (SNMP) has been enabled on each VM in the data center. The company cannot add more VMs in the data center and cannot install additional software on the VMs. The discovery data must be automatically imported into AWS Migration Hub.\n",
    "\n",
    "Which solution will meet these requirements?\n",
    "\n",
    "A. Use the AWS Application Migration Service agentless service and the AWS Migration Hub Strategy Recommendations to generate the TCO report.\n",
    "\n",
    "B. Launch a Windows Amazon EC2 instance. Install the Migration Evaluator agentless collector on the EC2 instance. Configure Migration Evaluator to generate the TCO report.\n",
    "\n",
    "C. Launch a Windows Amazon EC2 instance. Install the Migration Evaluator agentless collector on the EC2 instance. Configure Migration Hub to generate the TCO report.\n",
    "\n",
    "D. Use the AWS Migration Readiness Assessment tool inside the VPC. Configure Migration Evaluator to generate the TCO report.\n",
    "\n",
    "Solution:\n",
    "- correct answer is b\n",
    "- how to migrate Microsoft workload to aws\n",
    "  - Launch a Windows Amazon EC2 instance. \n",
    "  - Install the Migration Evaluator agentless collector on the EC2 instance. Configure Migration Evaluator to generate the TCO report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #467\n",
    "A company that is developing a mobile game is making game assets available in two AWS Regions. Game assets are served from a set of Amazon EC2 instances behind an Application Load Balancer (ALB) in each Region. The company requires game assets to be fetched from the closest Region. If game assets become unavailable in the closest Region, they should be fetched from the other Region.\n",
    "\n",
    "What should a solutions architect do to meet these requirements?\n",
    "\n",
    "A. Create an Amazon CloudFront distribution. Create an origin group with one origin for each ALB. Set one of the origins as primary.\n",
    "\n",
    "B. Create an Amazon Route 53 health check for each ALCreate a Route 53 failover routing record pointing to the two ALBs. Set the Evaluate Target Health value to Yes.\n",
    "\n",
    "C. Create two Amazon CloudFront distributions, each with one ALB as the origin. Create an Amazon Route 53 failover routing record pointing to the two CloudFront distributions. Set the Evaluate Target Health value to Yes.\n",
    "\n",
    "D. Create an Amazon Route 53 health check for each ALB. Create a Route 53 latency alias record pointing to the two ALBs. Set the Evaluate Target Health value to Yes.\n",
    "\n",
    "Solution:\n",
    "- correct answer is d\n",
    "- how to design assets distribution which fetch assets from closet  region\n",
    "  - Create an Amazon Route 53 health check for each ALB. Create a Route 53 latency alias record pointing to the two ALBs. Set the Evaluate Target Health value to Yes.\n",
    "    - using Route 53 latency alias record pointing to the two ALBs -> choose the fastest fetch\n",
    "  - can not choose a because CloudFront will get asset from primary orign first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #469\n",
    "A company wants to establish a dedicated connection between its on-premises infrastructure and AWS. The company is setting up a 1 Gbps AWS Direct Connect connection to its account VPC. The architecture includes a transit gateway and a Direct Connect gateway to connect multiple VPCs and the on-premises infrastructure.\n",
    "\n",
    "The company must connect to VPC resources over a transit VIF by using the Direct Connect connection.\n",
    "\n",
    "Which combination of steps will meet these requirements? (Choose two.)\n",
    "\n",
    "A. Update the 1 Gbps Direct Connect connection to 10 Gbps.\n",
    "\n",
    "B. Advertise the on-premises network prefixes over the transit VIF.\n",
    "\n",
    "C. Advertise the VPC prefixes from the Direct Connect gateway to the on-premises network over the transit VIF.\n",
    "\n",
    "D. Update the Direct Connect connection's MACsec encryption mode attribute to must_encrypt.\n",
    "\n",
    "E. Associate a MACsec Connection Key Name/Connectivity Association Key (CKN/CAK) pair with the Direct Connect connection.\n",
    "\n",
    "Solution:\n",
    "- correct anser is b, c\n",
    "- step to set up connection between on-premises with aws\n",
    "  - Advertise the on-premises network prefixes over the transit VIF -> on-premises side\n",
    "  - Advertise the VPC prefixes from the Direct Connect gateway to the on-premises network over the transit VIF. -> on vpc side\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #470\n",
    "A company wants to use Amazon WorkSpaces in combination with thin client devices to replace aging desktops. Employees use the desktops to access applications that work with Clinical trial data. Corporate security policy states that access to the applications must be restricted to only company branch office locations. The company is considering adding an additional branch office in the next 6 months.\n",
    "\n",
    "Which solution meets these requirements with the MOST operational efficiency?\n",
    "\n",
    "A. Create an IP access control group rule with the list of public addresses from the branch offices. Associate the IP access control group with the WorkSpaces directory.\n",
    "\n",
    "B. Use AWS Firewall Manager to create a web ACL rule with an IPSet with the list of public addresses from the branch office locations. Associate the web ACL with the WorkSpaces directory.\n",
    "\n",
    "C. Use AWS Certificate Manager (ACM) to issue trusted device certificates to the machines deployed in the branch office locations. Enable restricted access on the WorkSpaces directory.\n",
    "\n",
    "D. Create a custom WorkSpace image with Windows Firewall configured to restrict access to the public addresses of the branch offices. Use the image to deploy the WorkSpaces.\n",
    "\n",
    "Solution:\n",
    "- correct answer is a\n",
    "- what is access control to work with aws workspace\n",
    "  - Create an IP access control group rule with the list of public addresses from the branch offices. \n",
    "  - Associate the IP access control group with the WorkSpaces directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #471\n",
    "A company uses AWS Organizations. The company runs two firewall appliances in a centralized networking account. Each firewall appliance runs on a manually configured highly available Amazon EC2 instance. A transit gateway connects the VPC from the centralized networking account to VPCs of member accounts. Each firewall appliance uses a static private IP address that is then used to route traffic from the member accounts to the internet.\n",
    "\n",
    "During a recent incident, a badly configured script initiated the termination of both firewall appliances. During the rebuild of the firewall appliances, the company wrote a new script to configure the firewall appliances at startup.\n",
    "\n",
    "The company wants to modernize the deployment of the firewall appliances. The firewall appliances need the ability to scale horizontally to handle increased traffic when the network expands. The company must continue to use the firewall appliances to comply with company policy. The provider of the firewall appliances has confirmed that the latest version of the firewall code will work with all AWS services.\n",
    "\n",
    "Which combination of steps should the solutions architect recommend to meet these requirements MOST cost-effectively? (Choose three.)\n",
    "\n",
    "A. Deploy a Gateway Load Balancer in the centralized networking account. Set up an endpoint service that uses AWS PrivateLink.\n",
    "\n",
    "B. Deploy a Network Load Balancer in the centralized networking account. Set up an endpoint service that uses AWS PrivateLink.\n",
    "\n",
    "C. Create an Auto Scaling group and a launch template that uses the new script as user data to configure the firewall appliances. Create a target group that uses the instance target type.\n",
    "\n",
    "D. Create an Auto Scaling group. Configure an AWS Launch Wizard deployment that uses the new script as user data to configure the firewall appliances. Create a target group that uses the IP target type.\n",
    "\n",
    "E. Create VPC endpoints in each member account. Update the route tables to point to the VPC endpoints.\n",
    "\n",
    "F. Create VPC endpoints in the centralized networking account. Update the route tables in each member account to point to the VPC endpoints. \n",
    "\n",
    "Solution:\n",
    "- correct ansewr is a, c, f\n",
    "- how to scale firewall application with multiple vpc connected\n",
    "  - Deploy a Gateway Load Balancer in the centralized networking account. Set up an endpoint service that uses AWS PrivateLink.\n",
    "  - Create an Auto Scaling group and a launch template that uses the new script as user data to configure the firewall appliances. Create a target group that uses the instance target type.\n",
    "  - Create VPC endpoints in the centralized networking account. Update the route tables in each member account to point to the VPC endpoints. -> we need vpc endpoint at the central networking vpc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #472\n",
    "A solutions architect must implement a multi-Region architecture for an Amazon RDS for PostgreSQL database that supports a web application. The database launches from an AWS CloudFormation template that includes AWS services and features that are present in both the primary and secondary Regions.\n",
    "\n",
    "The database is configured for automated backups, and it has an RTO of 15 minutes and an RPO of 2 hours. The web application is configured to use an Amazon Route 53 record to route traffic to the database.\n",
    "\n",
    "Which combination of steps will result in a highly available architecture that meets all the requirements? (Choose two.)\n",
    "\n",
    "A. Create a cross-Region read replica of the database in the secondary Region. Configure an AWS Lambda function in the secondary Region to promote the read replica during a failover event.\n",
    "\n",
    "B. In the primary Region, create a health check on the database that will invoke an AWS Lambda function when a failure is detected. Program the Lambda function to recreate the database from the latest database snapshot in the secondary Region and update the Route 53 host records for the database.\n",
    "\n",
    "C. Create an AWS Lambda function to copy the latest automated backup to the secondary Region every 2 hours.\n",
    "\n",
    "D. Create a failover routing policy in Route 53 for the database DNS record. Set the primary and secondary endpoints to the endpoints in each Region.\n",
    "\n",
    "E. Create a hot standby database in the secondary Region. Use an AWS Lambda function to restore the secondary database to the latest RDS automatic backup in the event that the primary database fails.\n",
    "\n",
    "Solution:\n",
    "- correct answer is a, d\n",
    "- how to design back up plan for multi-region Amazon RDS for PostgreSQL database\n",
    "  - Create a cross-Region read replica of the database in the secondary Region. Configure an AWS Lambda function in the secondary Region to promote the read replica during a failover event.\n",
    "  - Create a failover routing policy in Route 53 for the database DNS record. Set the primary and secondary endpoints to the endpoints in each Region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #473\n",
    "An ecommerce company runs an application on AWS. The application has an Amazon API Gateway API that invokes an AWS Lambda function. The data is stored in an Amazon RDS for PostgreSQL DB instance.\n",
    "\n",
    "During the company’s most recent flash sale, a sudden increase in API calls negatively affected the application's performance. A solutions architect reviewed the Amazon CloudWatch metrics during that time and noticed a significant increase in Lambda invocations and database connections. The CPU utilization also was high on the DB instance.\n",
    "\n",
    "What should the solutions architect recommend to optimize the application's performance?\n",
    "\n",
    "A. Increase the memory of the Lambda function. Modify the Lambda function to close the database connections when the data is retrieved.\n",
    "\n",
    "B. Add an Amazon ElastiCache for Redis cluster to store the frequently accessed data from the RDS database.\n",
    "\n",
    "C. Create an RDS proxy by using the Lambda console. Modify the Lambda function to use the proxy endpoint.\n",
    "\n",
    "D. Modify the Lambda function to connect to the database outside of the function's handler. Check for an existing database connection before creating a new connection.\n",
    "\n",
    "Solution:\n",
    "- correct ansewr is c\n",
    "- how to deal with increase in Lambda invocations and database connections\n",
    "  - Create an RDS proxy by using the Lambda console. Modify the Lambda function to use the proxy endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #474\n",
    "A retail company wants to improve its application architecture. The company's applications register new orders, handle returns of merchandise, and provide analytics. The applications store retail data in a MySQL database and an Oracle OLAP analytics database. All the applications and databases are hosted on Amazon EC2 instances.\n",
    "\n",
    "Each application consists of several components that handle different parts of the order process. These components use incoming data from different sources. A separate ETL job runs every week and copies data from each application to the analytics database.\n",
    "\n",
    "A solutions architect must redesign the architecture into an event-driven solution that uses serverless services. The solution must provide updated analytics in near real time.\n",
    "\n",
    "Which solution will meet these requirements?\n",
    "\n",
    "A. Migrate the individual applications as microservices to Amazon Elastic Container Service (Amazon ECS) containers that use AWS Fargate. Keep the retail MySQL database on Amazon EC2. Move the analytics database to Amazon Neptune. Use Amazon Simple Queue Service (Amazon SQS) to send all the incoming data to the microservices and the analytics database.\n",
    "\n",
    "B. Create an Auto Scaling group for each application. Specify the necessary number of EC2 instances in each Auto Scaling group. Migrate the retail MySQL database and the analytics database to Amazon Aurora MySQL. Use Amazon Simple Notification Service (Amazon SNS) to send all the incoming data to the correct EC2 instances and the analytics database.\n",
    "\n",
    "C. Migrate the individual applications as microservices to Amazon Elastic Kubernetes Service (Amazon EKS) containers that use AWS Fargate. Migrate the retail MySQL database to Amazon Aurora Serverless MySQL. Migrate the analytics database to Amazon Redshift Serverless. Use Amazon EventBridge to send all the incoming data to the microservices and the analytics database.\n",
    "\n",
    "D. Migrate the individual applications as microservices to Amazon AppStream 2.0. Migrate the retail MySQL database to Amazon Aurora MySQL. Migrate the analytics database to Amazon Redshift Serverless. Use AWS IoT Core to send all the incoming data to the microservices and the analytics database.\n",
    "\n",
    "Solution:\n",
    "- correct answer is c\n",
    "- how to design near real time analytics solution\n",
    "  - Migrate the individual applications as microservices to Amazon Elastic Kubernetes Service (Amazon EKS) containers that use AWS Fargate. \n",
    "  - Migrate the retail MySQL database to Amazon Aurora Serverless MySQL. \n",
    "  - Migrate the analytics database to Amazon Redshift Serverless. \n",
    "  - Use Amazon EventBridge to send all the incoming data to the microservices and the analytics database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question #1351\n",
    "\n",
    "Which schema-level objects allow the user to periodically perform an action under specific conditions, based on data within Snowflake?\n",
    "\n",
    "A. Alerts\n",
    "\n",
    "B. External tables\n",
    "\n",
    "C. Secure views\n",
    "\n",
    "D. Materialized views\n",
    "\n",
    "Solution:\n",
    "- correct anser is A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question #1352\n",
    "\n",
    "Which privilege must be granted to show data categories in a Data Exchange?\n",
    "\n",
    "A. MONITOR PRIVILEGE\n",
    "\n",
    "B. USAGE PRIVILEGE\n",
    "\n",
    "C. OWNERSHIP PRIVILEGE\n",
    "\n",
    "D. IMPORTED PRIVILEGES\n",
    "\n",
    "Solution:\n",
    "- correct answer is D\n",
    "- reference link: https://docs.snowflake.com/en/user-guide/data-exchange-marketplace-privileges#granting-administrator-privileges-in-a-data-exchange"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
