{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #1\n",
    "\n",
    "A company needs to architect a hybrid DNS solution. This solution will use an Amazon Route 53 private hosted zone for the domain cloud.example.com for the resources stored within VPCs.\n",
    "The company has the following DNS resolution requirements:\n",
    "On-premises systems should be able to resolve and connect to cloud.example.com.\n",
    "All VPCs should be able to resolve cloud.example.com.\n",
    "There is already an AWS Direct Connect connection between the on-premises corporate network and AWS Transit Gateway.\n",
    "Which architecture should the company use to meet these requirements with the HIGHEST performance?\n",
    "\n",
    "A. Associate the private hosted zone to all the VPCs. Create a Route 53 inbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver.\n",
    "\n",
    "B. Associate the private hosted zone to all the VPCs. Deploy an Amazon EC2 conditional forwarder in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the conditional forwarder.\n",
    "\n",
    "C. Associate the private hosted zone to the shared services VPCreate a Route 53 outbound resolver in the shared services VPAttach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the outbound resolver.\n",
    "\n",
    "D. Associate the private hosted zone to the shared services VPC. Create a Route 53 inbound resolver in the shared services VPC. Attach the shared services VPC to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver.\n",
    "\n",
    "Solution:\n",
    "- correct answer is A\n",
    "- the question is about centralize DNS solution\n",
    "    - Associate the private hosted zone to all the VPCs\n",
    "    - Create a Route 53 inbound resolver in the shared services VPC\n",
    "    - Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #2\n",
    "\n",
    "A company is providing weather data over a REST-based API to several customers. The API is hosted by Amazon API Gateway and is integrated with different AWS Lambda functions for each API operation. The company uses Amazon Route 53 for DNS and has created a resource record of weather.example.com. The company stores data for the API in Amazon DynamoDB tables. The company needs a solution that will give the API the ability to fail over to a different AWS Region.\n",
    "Which solution will meet these requirements?\n",
    "\n",
    "A. Deploy a new set of Lambda functions in a new Region. Update the API Gateway API to use an edge-optimized API endpoint with Lambda functions from both Regions as targets. Convert the DynamoDB tables to global tables.\n",
    "\n",
    "B. Deploy a new API Gateway API and Lambda functions in another Region. Change the Route 53 DNS record to a multivalue answer. Add both API Gateway APIs to the answer. Enable target health monitoring. Convert the DynamoDB tables to global tables.\n",
    "\n",
    "C. Deploy a new API Gateway API and Lambda functions in another Region. Change the Route 53 DNS record to a failover record. Enable target health monitoring. Convert the DynamoDB tables to global tables.\n",
    "\n",
    "D. Deploy a new API Gateway API in a new Region. Change the Lambda functions to global functions. Change the Route 53 DNS record to a multivalue answer. Add both API Gateway APIs to the answer. Enable target health monitoring. Convert the DynamoDB tables to global tables.\n",
    "\n",
    "Solution:\n",
    "- correct answer is C\n",
    "- the question is about api gateway and lambda function need to have failover capability in multiple regions\n",
    "    - create new api gateway and lambda function in another regions -> api gateway and lambda function which in multiple regions\n",
    "    - Change the Route 53 DNS record to a failover record -> DNS record can handle in case of fail over\n",
    "    - Enable target health monitoring -> to know region is failling or not\n",
    "    - Convert the DynamoDB tables to global tables -> DynamoDb is replica in multiple regions (global tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #3\n",
    "\n",
    "A company uses AWS Organizations with a single OU named Production to manage multiple accounts. All accounts are members of the Production OU. Administrators use deny list SCPs in the root of the organization to manage access to restricted services.\n",
    "The company recently acquired a new business unit and invited the new unit’s existing AWS account to the organization. Once onboarded, the administrators of the new business unit discovered that they are not able to update existing AWS Config rules to meet the company’s policies.\n",
    "Which option will allow administrators to make changes and continue to enforce the current policies without introducing additional long-term maintenance?\n",
    "\n",
    "A. Remove the organization’s root SCPs that limit access to AWS Config. Create AWS Service Catalog products for the company’s standard AWS Config rules and deploy them throughout the organization, including the new account.\n",
    "\n",
    "B. Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the new account to the Production OU when adjustments to AWS Config are complete.\n",
    "\n",
    "C. Convert the organization’s root SCPs from deny list SCPs to allow list SCPs to allow the required services only. Temporarily apply an SCP to the organization’s root that allows AWS Config actions for principals only in the new account.\n",
    "\n",
    "D. Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the organization’s root SCP to the Production OU. Move the new account to the Production OU when adjustments to AWS Config are complete.\n",
    "\n",
    "Solution:\n",
    "- correct answer is D\n",
    "- the question is about relation between Oranization, SCP (Service Control Policy) and how to apply to change aws config\n",
    "    - because of SPC in root -> new unit account can not chnage aws config\n",
    "    - create new OU (Oranization Unit), config SCP on Onboarding OU which allo aws config \n",
    "    - move SCP from root to Production -> so that new account can change config\n",
    "    - move new account to Production when aws config is completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #4\n",
    "\n",
    "A company is running a two-tier web-based application in an on-premises data center. The application layer consists of a single server running a stateful application. The application connects to a PostgreSQL database running on a separate server. The application’s user base is expected to grow significantly, so the company is migrating the application and database to AWS. The solution will use Amazon Aurora PostgreSQL, Amazon EC2 Auto Scaling, and Elastic Load Balancing.\n",
    "Which solution will provide a consistent user experience that will allow the application and database tiers to scale?\n",
    "\n",
    "A. Enable Aurora Auto Scaling for Aurora Replicas. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled.\n",
    "\n",
    "B. Enable Aurora Auto Scaling for Aurora writers. Use an Application Load Balancer with the round robin routing algorithm and sticky sessions enabled.\n",
    "\n",
    "C. Enable Aurora Auto Scaling for Aurora Replicas. Use an Application Load Balancer with the round robin routing and sticky sessions enabled.\n",
    "\n",
    "D. Enable Aurora Scaling for Aurora writers. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled.\n",
    "\n",
    "Solution:\n",
    "- correct answer is C\n",
    "- the question is about solution which allow two tier application (application + database) to scale\n",
    "    - Enable Aurora Auto Scaling for Aurora Replicas -> allow database to scale\n",
    "    - Use an Application Load Balancer with the round robin routing and sticky sessions enabled -> better user experience (do not lost session data) when scale up or down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #5\n",
    "\n",
    "A company uses a service to collect metadata from applications that the company hosts on premises. Consumer devices such as TVs and internet radios access the applications. Many older devices do not support certain HTTP headers and exhibit errors when these headers are present in responses. The company has configured an on-premises load balancer to remove the unsupported headers from responses sent to older devices, which the company identified by the User-Agent headers.\n",
    "The company wants to migrate the service to AWS, adopt serverless technologies, and retain the ability to support the older devices. The company has already migrated the applications into a set of AWS Lambda functions.\n",
    "Which solution will meet these requirements?\n",
    "\n",
    "A. Create an Amazon CloudFront distribution for the metadata service. Create an Application Load Balancer (ALB). Configure the CloudFront distribution to forward requests to the ALB. Configure the ALB to invoke the correct Lambda function for each type of request. Create a CloudFront function to remove the problematic headers based on the value of the User-Agent header.\n",
    "\n",
    "B. Create an Amazon API Gateway REST API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Modify the default gateway responses to remove the problematic headers based on the value of the User-Agent header.\n",
    "\n",
    "C. Create an Amazon API Gateway HTTP API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Create a response mapping template to remove the problematic headers based on the value of the User-Agent. Associate the response data mapping with the HTTP API.\n",
    "\n",
    "D. Create an Amazon CloudFront distribution for the metadata service. Create an Application Load Balancer (ALB). Configure the CloudFront distribution to forward requests to the ALB. Configure the ALB to invoke the correct Lambda function for each type of request. Create a Lambda@Edge function that will remove the problematic headers in response to viewer requests based on the value of the User-Agent header.\n",
    "\n",
    "Solution:\n",
    "- correct answer is A\n",
    "- this question is aabout how to delivery response to client device base on request header, we need to support older device \n",
    "    - Create an Amazon CloudFront distribution for the metadata service. Create a CloudFront function to remove the problematic headers based on the value of the User-Agent header -> CloudFront function can help in remove un-wanted header\n",
    "    - Create an Application Load Balancer (ALB). Configure the CloudFront distribution to forward requests to the ALB. Configure the ALB to invoke the correct Lambda function for each type of request -> CloudFront forware request to Application Load Balancer, then ALB will invoke correct lambda function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question #6\n",
    "\n",
    "A retail company needs to provide a series of data files to another company, which is its business partner. These files are saved in an Amazon S3 bucket under Account A, which belongs to the retail company. The business partner company wants one of its IAM users, User_DataProcessor, to access the files from its own AWS account (Account B).\n",
    "Which combination of steps must the companies take so that User_DataProcessor can access the S3 bucket successfully? (Choose two.)\n",
    "\n",
    "Solution:\n",
    "- correct answer is C, D\n",
    "- is is about access s3 bucket from another account\n",
    "    - in account A allow user of account B to access s3 bucket\n",
    "    - in account B allow to access bucket from account a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #7\n",
    "\n",
    "A company is running a traditional web application on Amazon EC2 instances. The company needs to refactor the application as microservices that run on containers. Separate versions of the application exist in two distinct environments: production and testing. Load for the application is variable, but the minimum load and the maximum load are known. A solutions architect needs to design the updated application with a serverless architecture that minimizes operational complexity.\n",
    "Which solution will meet these requirements MOST cost-effectively?\n",
    "\n",
    "A. Upload the container images to AWS Lambda as functions. Configure a concurrency limit for the associated Lambda functions to handle the expected peak load. Configure two separate Lambda integrations within Amazon API Gateway: one for production and one for testing.\n",
    "\n",
    "B. Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Container Service (Amazon ECS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the ECS clusters.\n",
    "\n",
    "C. Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Kubernetes Service (Amazon EKS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the EKS clusters.\n",
    "\n",
    "D. Upload the container images to AWS Elastic Beanstalk. In Elastic Beanstalk, create separate environments and deployments for production and testing. Configure two separate Application Load Balancers to direct traffic to the Elastic Beanstalk deployments.\n",
    "\n",
    "Solution:\n",
    "- correct answer is B\n",
    "- the question is about change from ec2 to container based application but need to minized operational complexity and cost effective\n",
    "    - solution can be B or C. We choose C because Amazon Elastic Container Service is aws full managed which is recommened by aws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #8\n",
    "\n",
    "A company has a multi-tier web application that runs on a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB). The instances are in an Auto Scaling group. The ALB and the Auto Scaling group are replicated in a backup AWS Region. The minimum value and the maximum value for the Auto Scaling group are set to zero. An Amazon RDS Multi-AZ DB instance stores the application’s data. The DB instance has a read replica in the backup Region. The application presents an endpoint to end users by using an Amazon Route 53 record.\n",
    "The company needs to reduce its RTO to less than 15 minutes by giving the application the ability to automatically fail over to the backup Region. The company does not have a large enough budget for an active-active strategy.\n",
    "What should a solutions architect recommend to meet these requirements?\n",
    "\n",
    "A. Reconfigure the application’s Route 53 record with a latency-based routing policy that load balances traffic between the two ALBs. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Create an Amazon CloudWatch alarm that is based on the HTTPCode_Target_5XX_Count metric for the ALB in the primary Region. Configure the CloudWatch alarm to invoke the Lambda function.\n",
    "\n",
    "B. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Configure Route 53 with a health check that monitors the web application and sends an Amazon Simple Notification Service (Amazon SNS) notification to the Lambda function when the health check status is unhealthy. Update the application’s Route 53 record with a failover policy that routes traffic to the ALB in the backup Region when a health check failure occurs.\n",
    "\n",
    "C. Configure the Auto Scaling group in the backup Region to have the same values as the Auto Scaling group in the primary Region. Reconfigure the application’s Route 53 record with a latency-based routing policy that load balances traffic between the two ALBs. Remove the read replica. Replace the read replica with a standalone RDS DB instance. Configure Cross-Region Replication between the RDS DB instances by using snapshots and Amazon S3.\n",
    "\n",
    "D. Configure an endpoint in AWS Global Accelerator with the two ALBs as equal weighted targets. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Create an Amazon CloudWatch alarm that is based on the HTTPCode_Target_5XX_Count metric for the ALB in the primary Region. Configure the CloudWatch alarm to invoke the Lambda function.\n",
    "\n",
    "Solution:\n",
    "- correct anser is B\n",
    "- the question is about desing multi-tier application which allow failover backup region\n",
    "    - Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values -> lambda function to promote read replica and change config for auto scaling group\n",
    "    - Configure Route 53 with a health check that monitors the web application and sends an Amazon Simple Notification Service (Amazon SNS) notification to the Lambda function when the health check status is unhealthy -> health check at route 53 to check for failover, send notification to SNS topics to invoke lambda function\n",
    "    - Update the application’s Route 53 record with a failover policy that routes traffic to the ALB in the backup Region when a health check failure occurs. -> route traffic to alb in backup regions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
